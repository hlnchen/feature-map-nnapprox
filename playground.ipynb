{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from torch import asin\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import layers\n",
    "\n",
    "import importlib\n",
    "importlib.reload(layers)\n",
    "from layers import LinearArcsine, RandomFeatureMap, ArcsinNN, RepresentArcsineNN, ApproxArcsineNN\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(20,784).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0193,  0.0607,  0.1705,  0.0276,  0.0770,  0.1142, -0.1347, -0.0080,\n",
       "         -0.0188,  0.0393],\n",
       "        [ 0.0146,  0.0361,  0.0222,  0.0258,  0.0262,  0.0227, -0.0133, -0.0590,\n",
       "          0.0122,  0.0920],\n",
       "        [-0.0618, -0.0546,  0.0774, -0.0041, -0.0546,  0.0093,  0.0008, -0.0218,\n",
       "          0.0288, -0.0034],\n",
       "        [-0.0102,  0.1099, -0.0425,  0.0238,  0.0185, -0.0003, -0.0247, -0.0334,\n",
       "         -0.0026,  0.0023],\n",
       "        [-0.0467,  0.0672,  0.1156,  0.0317,  0.0590,  0.0959, -0.0233,  0.0441,\n",
       "          0.0401,  0.0361],\n",
       "        [-0.0091, -0.0338,  0.0148,  0.0977, -0.0476, -0.0313, -0.0150,  0.0166,\n",
       "          0.0621,  0.0810],\n",
       "        [ 0.0230,  0.0577,  0.0270,  0.0013,  0.0385,  0.0475,  0.0389, -0.0956,\n",
       "          0.0497,  0.0098],\n",
       "        [-0.0619,  0.0193, -0.0154,  0.0009,  0.0222, -0.0362, -0.0589, -0.0882,\n",
       "          0.0404,  0.0248],\n",
       "        [ 0.0503,  0.0725, -0.0069,  0.0426,  0.0293,  0.1456,  0.0064, -0.1217,\n",
       "         -0.0243,  0.0983],\n",
       "        [-0.0683,  0.0232,  0.0247,  0.1157,  0.0925,  0.0148, -0.0356,  0.0280,\n",
       "         -0.0251,  0.0012],\n",
       "        [ 0.0344,  0.0200, -0.0513,  0.0698, -0.0219,  0.0063, -0.0245,  0.0137,\n",
       "          0.0253, -0.0111],\n",
       "        [ 0.0067, -0.0418,  0.0244,  0.0292, -0.0213,  0.0405, -0.0976,  0.0110,\n",
       "         -0.0569,  0.0712],\n",
       "        [-0.0184,  0.0369,  0.0454,  0.0230, -0.0886,  0.0651,  0.0234,  0.0119,\n",
       "          0.0398,  0.0191],\n",
       "        [-0.0307,  0.0043,  0.0041,  0.0090,  0.0889,  0.0635, -0.0361, -0.0304,\n",
       "          0.0321,  0.1607],\n",
       "        [-0.0091,  0.0353,  0.0160,  0.0981,  0.0236,  0.0759,  0.0119, -0.1476,\n",
       "          0.0532,  0.0846],\n",
       "        [ 0.0380,  0.0640, -0.0296,  0.0642, -0.0061,  0.1173, -0.0591, -0.0594,\n",
       "          0.0305,  0.0886],\n",
       "        [-0.0435,  0.0549, -0.0085, -0.0021, -0.0148,  0.0340, -0.0793,  0.0257,\n",
       "         -0.0498,  0.0271],\n",
       "        [ 0.0083,  0.0256,  0.0373,  0.0420,  0.0285,  0.0419, -0.0133,  0.0481,\n",
       "         -0.0362,  0.0107],\n",
       "        [-0.0098, -0.0034, -0.0331,  0.0439,  0.0293,  0.0729, -0.0415, -0.0059,\n",
       "         -0.0082,  0.0624],\n",
       "        [ 0.0243, -0.0183, -0.0218,  0.1481, -0.0698,  0.0564,  0.0131, -0.0420,\n",
       "          0.0171,  0.0331]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ArcsinNN(in_features=784, out_features=10, hidden_features=[1024]*3, bias=True).to(device)\n",
    "approx_factoring_scratch = RepresentArcsineNN(model, seed=20220904, ignore_first_layer=False, project_dim=500).to(device)\n",
    "approx_factoring_scratch(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepresentArcsineNN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Linears): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=False)\n",
      "    (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "  )\n",
      "  (Output): Linear(in_features=1024, out_features=10, bias=True)\n",
      ") {784: RandomFeatureMap(\n",
      "  (weights): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 784x2000 (GPU 0)])\n",
      "), 2000: RandomFeatureMap(\n",
      "  (weights): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 2000x2000 (GPU 0)])\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "print(approx_factoring_scratch, approx_factoring_scratch.RandomFeatureMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArcsinNN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Layers): Sequential(\n",
      "    (LinearArcsine0): LinearArcsine(in_features=100, out_features=200, bias=True)\n",
      "    (Output): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_approximated = ApproxArcsineNN(model,project_dim=5000)\n",
    "model_approximated_with_composition = RepresentArcsineNN(model,project_dim=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApproxArcsineNN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Linears): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "  )\n",
      "  (Output): Linear(in_features=200, out_features=10, bias=True)\n",
      ") \n",
      " RepresentArcsineNN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Linears): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "  )\n",
      "  (Output): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "{100: RandomFeatureMap(\n",
      "  (weights): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 101x5000])\n",
      ")} \n",
      " {0: RandomFeatureMap(\n",
      "  (weights): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 101x5000])\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "print(model_approximated, \"\\n\", model_approximated_with_composition)\n",
    "print(model_approximated.RandomFeatureMaps, \"\\n\", model_approximated_with_composition.RandomFeatureMaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_approximated.RandomFeatureMaps[100] = model_approximated_with_composition.RandomFeatureMaps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6115e-07, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(model_approximated(X) - model_approximated_with_composition(X))/torch.norm(model_approximated_with_composition(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArcsinNN(in_features=100, hidden_features=[100,200,300], out_features=10,bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApproxArcsineNN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Linears): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=300, bias=True)\n",
      "  )\n",
      "  (Output): Linear(in_features=300, out_features=10, bias=True)\n",
      ") \n",
      " {200: RandomFeatureMap(\n",
      "  (weights): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 201x201 (GPU 0)])\n",
      "), 100: RandomFeatureMap(\n",
      "  (weights): ParameterList(  (0): Parameter containing: [torch.cuda.FloatTensor of size 101x101 (GPU 0)])\n",
      ")}\n",
      "RepresentArcsineNN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (Linears): ModuleList(\n",
      "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (1): Linear(in_features=100, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=300, bias=True)\n",
      "  )\n",
      "  (Output): Linear(in_features=300, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_approximated = ApproxArcsineNN(model)\n",
    "model_approximated_with_composition = RepresentArcsineNN(model, ignore_first_layer=False).to(device)\n",
    "print(model_approximated, \"\\n\", model_approximated.RandomFeatureMaps)\n",
    "print(model_approximated_with_composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 10])\n",
      "torch.Size([50, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn((50,100)).to(device)\n",
    "print(model_approximated(X).shape)\n",
    "print(model_approximated_with_composition(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArcsinNN(in_features=100, out_features=10, hidden_features=[100,200,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_approximated_with_composition = RepresentArcsineNN(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (101x100 and 101x101)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20292/2151764115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_approximated_with_composition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Haolin\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Haolin\\Desktop\\feature-map-nnapprox\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    257\u001b[0m                     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinears\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinears\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m                     \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomFeatureMaps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_first_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Haolin\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Haolin\\Desktop\\feature-map-nnapprox\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Haolin\\Desktop\\feature-map-nnapprox\\layers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (101x100 and 101x101)"
     ]
    }
   ],
   "source": [
    "X = torch.randn(50,100)\n",
    "model_approximated_with_composition(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07315ba070dea1980208edb5f4fd988df0f55a182694c2201b33f2c556751b3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
